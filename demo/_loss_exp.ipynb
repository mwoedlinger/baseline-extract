{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some experiments regarding the loss function for the line finder framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append('C:\\\\Users\\\\matthias\\\\Documents\\\\myProjects\\\\TU_Bibliothek\\\\code\\\\baseline-extract')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy.optimize import linear_sum_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "pred = torch.tensor([[56,124,0.1, 55, 0.8], [2,54,0.12, 52, 0.3], [102, 95, 0.05, 59, 0.99], [193,234, -0.2, 51, 0.9], [654,234, 0.25, 52, 0.6], [4,3450, 0.8, 32, 0.1], [345,6, 0.12, 57, 0.6], [23,634, 0.18, 45, 0.3], [345,64,0.1, 55, 0.8]])\n",
    "label = torch.tensor([[100,100, 0, 64], [200,200, 0.1, 64], [300,300, 0.05, 64]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = torch.tensor([[100, 100,0.1, 55, 0.99], [200,200,0.12, 52, 0.99], [300, 300, 0.05, 59, 0.99], [193,234, -0.2, 51, 0.009], [654,234, 0.25, 52, 0.006], [4,3450, 0.8, 32, 0.001], [345,6, 0.12, 57, 0.006], [23,634, 0.18, 45, 0.003], [345,64,0.1, 55, 0.008]])\n",
    "label = torch.tensor([[100,100, 0, 64], [200,200, 0.1, 64], [300,300, 0.05, 64]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 5])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred.float()\n",
    "label = label.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crit(label[0], pred[0,0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = pred.shape[0]\n",
    "M = label.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = torch.zeros(N, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(N):\n",
    "    for m in range(M):\n",
    "        cost[n, m] = crit(pred[n,0:2], label[m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = linear_sum_assignment(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2560e+03, 1.3256e+04, 4.5256e+04],\n",
       "        [5.8600e+03, 3.0260e+04, 7.4660e+04],\n",
       "        [1.4500e+01, 1.0314e+04, 4.0614e+04],\n",
       "        [1.3262e+04, 2.5625e+03, 1.1862e+04],\n",
       "        [1.6244e+05, 1.0364e+05, 6.4836e+04],\n",
       "        [5.6159e+06, 5.3005e+06, 5.0051e+06],\n",
       "        [3.4430e+04, 2.9330e+04, 4.4230e+04],\n",
       "        [1.4554e+05, 1.0984e+05, 9.4142e+04],\n",
       "        [3.0660e+04, 1.9760e+04, 2.8860e+04]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 2, 3], dtype=int64), array([0, 1, 2], dtype=int64))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import time\n",
    "from src.utils.distances import point_line_distance\n",
    "\n",
    "\n",
    "class LineFinderLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.01):\n",
    "        super(LineFinderLoss, self).__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, pred, label):\n",
    "        batch_size = pred.shape[0]\n",
    "        n_tot = pred.shape[1]\n",
    "        m_tot = label.shape[1]\n",
    "\n",
    "        loss = 0\n",
    "\n",
    "        for b in range(batch_size):\n",
    "            # I get P predictions and T true labels.\n",
    "            inp = pred[b, :, 0:4]\n",
    "            targ = label[b, :, :]\n",
    "\n",
    "            conf_scores = pred[b, :, 4]\n",
    "            print(conf_scores)\n",
    "\n",
    "            # Compute the confidence for all P predictions.\n",
    "            log_c = torch.log(conf_scores + 0.00001)\n",
    "            log_c_anti = torch.log(1 - conf_scores + 0.00001)\n",
    "\n",
    "            # Expand such that for all T true lables I have a row of all predicted confidence logs.\n",
    "            # The result is a P x T matrix.\n",
    "            log_c_exp = log_c[:, None].expand(-1, targ.shape[0])\n",
    "            log_c_anti_exp = log_c_anti[:, None].expand(-1, targ.shape[0])\n",
    "\n",
    "            # Expand such that I get P x T x 4 matrices.\n",
    "            inp_exp = inp[:, None, :].expand(-1, targ.shape[0], -1)\n",
    "            targ_exp = targ[None, :, :].expand(inp.shape[0], -1, -1)\n",
    "\n",
    "            # Compute the difference between every pair of prediction and true label locations.\n",
    "            diff = (inp_exp[:, :, 0:4] - targ_exp[:, :, 0:4])\n",
    "            normed_diff = torch.norm(diff, 2, 2) ** 2\n",
    "\n",
    "            # Loss = Sum_{n=0}^N Sum_{m=0}^M    X_nm [alpha*MSE(l_n, p_m) - Log(c_m)] - (1- X_nm) Log(1-c_m)\n",
    "            # where:\n",
    "            #   N:      prediction dimension\n",
    "            #   M:      label dimension\n",
    "            #   X_mn:   linear assignement matrix\n",
    "            #   l_n:    label coordinates\n",
    "            #   p_m:    prediction coordinates\n",
    "            #   c_m:    confidence scores\n",
    "\n",
    "            # Compute the cost matrix. This is a P x T matrix.\n",
    "            C = self.alpha*normed_diff - log_c_exp + log_c_anti_exp\n",
    "\n",
    "            X = torch.zeros(C.shape)\n",
    "            x_c = torch.ones(C.shape[0])\n",
    "\n",
    "            # For every column index (true), compute the row index (pred) where the cost is minimal.\n",
    "            inp_idx, targ_idx = linear_sum_assignment(C)\n",
    "            X[(inp_idx, targ_idx)] = 1.0\n",
    "            x_c[inp_idx] = 0.0\n",
    "            \n",
    "            location_loss = (self.alpha*normed_diff*X).sum()\n",
    "            confidence_loss = -(log_c_exp*X).sum() - (log_c_anti*x_c).sum()\n",
    "\n",
    "            loss = location_loss + confidence_loss\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfl = LineFinderLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pred.unsqueeze(0)\n",
    "l = label.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9900, 0.9900, 0.9900, 0.0090, 0.0060, 0.0010, 0.0060, 0.0030, 0.0080])\n"
     ]
    }
   ],
   "source": [
    "d = lfl(p,l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9900, 0.9900, 0.9900, 0.0090, 0.0060, 0.0010, 0.0060, 0.0030, 0.0080])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(2.5633)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfl(p,l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5633)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 0., 1.],\n",
       "        [1., 1., 0.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
